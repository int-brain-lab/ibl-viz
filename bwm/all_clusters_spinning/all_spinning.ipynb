{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video of brain spinning with all clusters, organized by insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dan\\anaconda3\\envs\\iblenv\\lib\\site-packages\\neurodsp\\__init__.py:5: FutureWarning: neurodsp has been renamed to ibldsp and the old name will be deprecated on 01-Sep-2024.\n",
      "  warn(\n",
      "c:\\Users\\Dan\\anaconda3\\envs\\iblenv\\lib\\site-packages\\ibllib\\atlas\\__init__.py:202: DeprecationWarning: ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use this module instead\n",
      "  warnings.warn('ibllib.atlas is deprecated. Please install iblatlas using \"pip install iblatlas\" and use '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading bwm_query results from fixtures/2023_12_bwm_release.csv\n",
      "Loading bwm_query results from fixtures/2023_12_bwm_release.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dan\\anaconda3\\envs\\iblenv\\lib\\site-packages\\ibllib\\atlas\\atlas.py:13: DeprecationWarning: ibllib.atlas.regions.BrainRegions is deprecated. Use iblatlas.regions.BrainRegions instead\n",
      "  warnings.warn(warning_text, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from brainwidemap import bwm_query, bwm_units\n",
    "from one.api import ONE\n",
    "\n",
    "one = ONE(base_url='https://openalyx.internationalbrainlab.org')\n",
    "# Dataframe with info on all sessions and probes released for the BWM\n",
    "bwm_df = bwm_query(one)\n",
    "# Dataframe with information on all neurons used in the analyses in the BWM paper\n",
    "unit_df = bwm_units(one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from one.api import ONE\n",
    "import ephys_atlas.data\n",
    "\n",
    "LABEL = '2024_W04'  # 2023_W51_autism for example would return the autism dataset features\n",
    "LOCAL_DATA_PATH = Path('C:/scratch/')\n",
    "one = ONE(base_url=\"https://alyx.internationalbrainlab.org\", mode='local')\n",
    "\n",
    "df_raw_features, df_clusters, df_channels, df_probes = ephys_atlas.data.download_tables(\n",
    "    label=LABEL, local_path=LOCAL_DATA_PATH, one=one)\n",
    "# df_raw_features, df_clusters, df_channels = load_tables(local_path=FOLDER_GDRIVE)\n",
    "\n",
    "# df_depths = ephys_atlas.data.compute_depth_dataframe(df_raw_features, df_clusters, df_channels)\n",
    "df_voltage = df_raw_features.merge(df_channels, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "## %%\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "sns.countplot(data=df_clusters, x='label',  palette='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwm_df.loc[bwm_df['lab'] == 'hoferlab', 'lab'] = 'hoferflogellab'\n",
    "bwm_df.loc[bwm_df['lab'] == 'mrsicflogellab', 'lab'] = 'hoferflogellab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iblatlas import atlas\n",
    "aa = atlas.AllenAtlas()\n",
    "from iblatlas.regions import BrainRegions\n",
    "br = BrainRegions()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_to_rgb(hex_color):\n",
    "    # Remove '#' if present\n",
    "    if hex_color.startswith('#'):\n",
    "        hex_color = hex_color[1:]\n",
    "\n",
    "    # Convert hex to RGB\n",
    "    red = int(hex_color[0:2], 16) / 255.0\n",
    "    green = int(hex_color[2:4], 16) / 255.0\n",
    "    blue = int(hex_color[4:6], 16) / 255.0\n",
    "\n",
    "    return red, green, blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ulabs = np.unique(bwm_df.lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_data = []\n",
    "\n",
    "id2color = {}\n",
    "\n",
    "for lab in ulabs:\n",
    "    pids = bwm_df.pid[bwm_df.lab == lab]\n",
    "    \n",
    "    # print((lab, len(pids)))\n",
    "\n",
    "\n",
    "    coords = []\n",
    "\n",
    "    for pid in pids:\n",
    "        units = unit_df[unit_df.pid==pid]\n",
    "        # print(len(units))\n",
    "        for i, unit in units.iterrows():\n",
    "            coord = aa.xyz2ccf([unit.x, unit.y, unit.z])\n",
    "            if unit.atlas_id in id2color.keys():\n",
    "                color = id2color[unit.atlas_id]\n",
    "            else:\n",
    "                color = hex_to_rgb(aa.regions.hexcolor[aa.regions.id2index(unit.atlas_id)[1][0][0]])\n",
    "                id2color[unit.atlas_id] = color\n",
    "            coords.append([coord, color])\n",
    "\n",
    "    lab_df = pd.DataFrame(columns=['mlapdv', 'color'], data=coords)\n",
    "\n",
    "    lab_data.append(lab_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angelakilab' 'churchlandlab' 'churchlandlab_ucla' 'cortexlab' 'danlab'\n",
      " 'hausserlab' 'hoferflogellab' 'mainenlab' 'steinmetzlab' 'wittenlab'\n",
      " 'zadorlab']\n"
     ]
    }
   ],
   "source": [
    "# contributions\n",
    "print(ulabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# institution_map = {'cortexlab': 'UCL', 'mainenlab': 'CCU', 'zadorlab': 'CSHL (Z)',\n",
    "#                        'churchlandlab': 'CSHL (C)', 'angelakilab': 'NYU',\n",
    "#                        'wittenlab': 'Princeton', 'hoferlab': 'SWC', 'mrsicflogellab': 'SWC',\n",
    "#                        'danlab': 'Berkeley', 'steinmetzlab': 'UW', 'churchlandlab_ucla': 'UCLA', 'hausserlab':'UCL'}\n",
    "institution_map = {'cortexlab': 'Carandini & Harris Labs (University College London)', 'mainenlab': 'Mainen Lab (Champalimaud Center for the Unknown)',\n",
    "                   'zadorlab': 'Zador Lab (Cold Spring Harbor)', 'churchlandlab': 'Churchland Lab (Cold Spring Harbor)',\n",
    "                   'angelakilab': 'Angelaki Lab (New York University)', 'wittenlab': 'Witten Lab (Princeton University)', \n",
    "                   'hoferflogellab': 'Hofer & Mrsic-Flogel Labs (Sainsbury-Wellcome Centre)',\n",
    "                   'danlab': 'Dan Lab (University of California, Berkeley)', 'steinmetzlab': 'Steinmetz Lab (University of Washington)',\n",
    "                   'churchlandlab_ucla': 'Churchland Lab (University of California, Los Angeles)', 'hausserlab': 'Hausser Lab (University College London)'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_clean = [institution_map[lab] for lab in ulabs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Angelaki Lab (New York University)',\n",
       " 'Churchland Lab (Cold Spring Harbor)',\n",
       " 'Churchland Lab (University of California, Los Angeles)',\n",
       " 'Carandini & Harris Labs (University College London)',\n",
       " 'Dan Lab (University of California, Berkeley)',\n",
       " 'Hausser Lab (University College London)',\n",
       " 'Hofer & Mrsic-Flogel Labs (Sainsbury-Wellcome Centre)',\n",
       " 'Mainen Lab (Champalimaud Center for the Unknown)',\n",
       " 'Steinmetz Lab (University of Washington)',\n",
       " 'Witten Lab (Princeton University)',\n",
       " 'Zador Lab (Cold Spring Harbor)']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_contribs = ['Julius Benson, Jean-Paul Noel',\n",
    "                  'Anne Urai',\n",
    "                  'Anup Khanal, Felicia Davatolhagh',\n",
    "                  'Karolina Socha',\n",
    "                  'Fei Hu',\n",
    "                  'Petrina Lau',\n",
    "                  'Nathaniel Miska',\n",
    "                  'Guido Meijer',\n",
    "                  'Noam Roth',\n",
    "                  'Alejandro Pan-Vazquez',\n",
    "                  'Christpher Krasniak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_colors = np.concatenate([sns.color_palette(\"Dark2\"), sns.color_palette('Set2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(URN) connected to server\n",
      "Login sent with ID: test, copy this ID into the renderer to connect.\n"
     ]
    }
   ],
   "source": [
    "import oursin as urchin\n",
    "urchin.setup(id='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Warning) Atlas was already loaded, the renderer can have issues if you try to load an atlas twice.\n"
     ]
    }
   ],
   "source": [
    "# Load root\n",
    "urchin.ccf25.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin.ccf25.root.set_visibility(True, side=urchin.utils.Side.FULL)\n",
    "urchin.ccf25.root.set_color([0,0,0])\n",
    "urchin.ccf25.root.set_material('transparent-lit')\n",
    "urchin.ccf25.root.set_alpha(0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "urchin.camera.main.set_rotation([-45, 0, 0])\n",
    "urchin.camera.set_brain_rotation(225)\n",
    "urchin.camera.main.set_zoom(50)\n",
    "urchin.camera.main.set_mode('perspective')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = urchin.text.Text()\n",
    "text.set_position([-0.5, -0.75])\n",
    "text.set_color('#ffffff')\n",
    "text.set_font_size(64)\n",
    "text.set_position([-0.92, -0.75])\n",
    "\n",
    "contrib_text = urchin.text.Text()\n",
    "contrib_text.set_position([-0.5, -0.85])\n",
    "contrib_text.set_color('#ffffff')\n",
    "contrib_text.set_font_size(48)\n",
    "contrib_text.set_position([-0.92, -0.85])\n",
    "\n",
    "# text.set_text(\"test\")\n",
    "# contrib_text.set_text(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-create all neurons and store them in lists\n",
    "all_meshes = []\n",
    "all_colors = []\n",
    "neurons_by_lab = {}\n",
    "\n",
    "for i, lab_df in enumerate(lab_data):\n",
    "    \n",
    "    ccolor = list(lab_colors[i])\n",
    "    meshes = urchin.meshes.create(len(lab_df))\n",
    "    all_meshes = all_meshes + meshes\n",
    "    positions = []\n",
    "    colors = []\n",
    "    \n",
    "    for j, row in lab_df.iterrows():\n",
    "        positions.append([row.mlapdv[1], row.mlapdv[0], row.mlapdv[2]])\n",
    "        colors.append(ccolor)\n",
    "        all_colors.append(row.color)\n",
    "    \n",
    "    urchin.meshes.set_positions(meshes, positions)\n",
    "    urchin.meshes.set_colors(meshes, colors)\n",
    "    urchin.meshes.set_scales(meshes, [[0,0,0]]*len(meshes))\n",
    "\n",
    "    neurons_by_lab[i] = meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(990, 1020, 1200)\n"
     ]
    }
   ],
   "source": [
    "s_per_build = 2\n",
    "s_per_lab = 3\n",
    "s_pause = 1\n",
    "s_end = 6\n",
    "fps = 30\n",
    "\n",
    "lab_frames = fps*len(ulabs)*s_per_lab\n",
    "pause_frames = lab_frames + s_pause * fps\n",
    "total_frames = pause_frames + s_end * fps\n",
    "total_s = s_per_lab*len(ulabs) + s_pause + s_end\n",
    "print((lab_frames, pause_frames, total_frames))\n",
    "\n",
    "frames_per_build = s_per_build * fps\n",
    "frames_per_lab = s_per_lab*fps\n",
    "lab_meshes = []\n",
    "\n",
    "pause_set = False\n",
    "end_set = False\n",
    "\n",
    "def set_view(frame):   \n",
    "    global lab_idx, ccolor, lab_meshes, lab_frames, pause_frames, pause_set, pause_frames, end_set\n",
    "\n",
    "    urchin.camera.set_brain_rotation(225 + frame * 0.75)\n",
    "    \n",
    "    if (frame < lab_frames):\n",
    "        if np.mod(frame, frames_per_lab) == 0:\n",
    "            if lab_meshes:\n",
    "                urchin.meshes.set_scales(lab_meshes, [[0,0,0]]*len(lab_meshes))\n",
    "\n",
    "            lab_idx = int(np.floor(frame / frames_per_lab))\n",
    "            ccolor = list(lab_colors[lab_idx])\n",
    "\n",
    "            text.set_text(names_clean[lab_idx])\n",
    "            text.set_color(ccolor)\n",
    "\n",
    "            contrib_text.set_text(names_contribs[lab_idx])\n",
    "            contrib_text.set_color(ccolor)\n",
    "\n",
    "            lab_meshes = neurons_by_lab[lab_idx]\n",
    "\n",
    "        perc = np.min([np.mod(frame, frames_per_lab) / frames_per_build, 1])\n",
    "        num_meshes = int(np.floor(len(lab_meshes) * perc))\n",
    "\n",
    "        urchin.meshes.set_scales(lab_meshes[0:num_meshes], [[0.04, 0.04, 0.04]]*num_meshes)\n",
    "    \n",
    "    elif (frame < pause_frames):\n",
    "        if not pause_set:\n",
    "            pause_set = True\n",
    "\n",
    "            text.set_text(\"\")\n",
    "            contrib_text.set_text(\"\")\n",
    "            \n",
    "            urchin.meshes.set_scales(lab_meshes, [[0, 0, 0]]*len(lab_meshes))\n",
    "\n",
    "    else:\n",
    "        if not end_set:\n",
    "            end_set = True\n",
    "\n",
    "            text.set_text(\"International Brain Laboratory\")\n",
    "            text.set_color([0,0,0])\n",
    "            contrib_text.set_text(\"Brain Wide Map\")\n",
    "            contrib_text.set_color([0,0,0])\n",
    "            urchin.meshes.set_colors(all_meshes, all_colors)\n",
    "            urchin.meshes.set_scales(all_meshes, [[0.04, 0.04, 0.04]]*len(all_meshes))\n",
    "\n",
    "all_meshes = []\n",
    "for i in np.arange(0,len(neurons_by_lab)):\n",
    "    all_meshes = all_meshes + neurons_by_lab[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test mode\n",
    "for i in np.arange(0, total_frames):\n",
    "    if np.mod(i, 10)==0:\n",
    "        set_view(i)\n",
    "        time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n",
      "(Camera receive) Camera CameraMain received an image\n",
      "(Camera receive) CameraMain complete\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [114], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m urchin\u001b[38;5;241m.\u001b[39mcamera\u001b[38;5;241m.\u001b[39mmain\u001b[38;5;241m.\u001b[39mcapture_video(file_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmov.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m, callback\u001b[38;5;241m=\u001b[39mset_view, duration\u001b[38;5;241m=\u001b[39mtotal_s)\n",
      "File \u001b[1;32mC:\\proj\\VBL\\Urchin\\API\\oursin\\camera.py:370\u001b[0m, in \u001b[0;36mCamera.capture_video\u001b[1;34m(self, file_name, callback, start_rotation, end_rotation, frame_rate, duration, size, test)\u001b[0m\n\u001b[0;32m    364\u001b[0m \tclient\u001b[38;5;241m.\u001b[39msio\u001b[38;5;241m.\u001b[39memit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murchin-camera-lerp\u001b[39m\u001b[38;5;124m'\u001b[39m, FloatData(\n\u001b[0;32m    365\u001b[0m \t\t\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    366\u001b[0m \t\tvalue\u001b[38;5;241m=\u001b[39mperc\n\u001b[0;32m    367\u001b[0m \t)\u001b[38;5;241m.\u001b[39mto_string())\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m test:\n\u001b[1;32m--> 370\u001b[0m \timg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscreenshot([size[\u001b[38;5;241m0\u001b[39m], size[\u001b[38;5;241m1\u001b[39m]])\n\u001b[0;32m    371\u001b[0m \timage_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img)\n\u001b[0;32m    372\u001b[0m \timage_array \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image_array, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2BGR)\n",
      "File \u001b[1;32mC:\\proj\\VBL\\Urchin\\API\\oursin\\camera.py:294\u001b[0m, in \u001b[0;36mCamera.screenshot\u001b[1;34m(self, size, filename)\u001b[0m\n\u001b[0;32m    291\u001b[0m client\u001b[38;5;241m.\u001b[39msio\u001b[38;5;241m.\u001b[39memit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murchin-camera-screenshot-request\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m.\u001b[39mto_string())\n\u001b[0;32m    293\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_received:\n\u001b[1;32m--> 294\u001b[0m \t\u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# await self.image_received_event.wait()\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \n\u001b[0;32m    297\u001b[0m \u001b[38;5;66;03m# image is here, reconstruct it\u001b[39;00m\n\u001b[0;32m    298\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(receive_bytes[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mid]))\n",
      "File \u001b[1;32mc:\\Users\\Dan\\anaconda3\\envs\\iblenv\\lib\\asyncio\\tasks.py:605\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(delay, result)\u001b[0m\n\u001b[0;32m    601\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[0;32m    602\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[0;32m    603\u001b[0m                     future, result)\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 605\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    607\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "\u001b[1;31mCancelledError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Camera receive) Camera CameraMain received an image\n"
     ]
    }
   ],
   "source": [
    "await urchin.camera.main.capture_video(file_name='mov.mp4', callback=set_view, duration=total_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainwidemap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
